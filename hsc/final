\title{Applying Feature Selection to Gene Expression Data: Cell-type Classification \& Gene Signature Identification.}
\author{
        \textsc{Gustavo Empinotti}
            \qquad
        \textsc{Susan Tu}
            \qquad
        \textsc{Raf Mertens}
        \mbox{}\\ %
        \\
        CS229\\
        \mbox{}\\ %
        \normalsize
            \texttt{gustavoe}
        \textbar{}
            \texttt{susanctu}
        \textbar{}
            \texttt{rafm}
        \normalsize
            \texttt{@stanford.edu}
}
\date{\today}
\documentclass[10.75pt]{article}
%\documentclass{acmconf}
%\usepackage[pdftex]{graphicx}
%\usepackage[paper=a4paper,dvips,top=2cm,left=1.5cm,right=1.5cm,
%    foot=3cm,bottom=3cm]{geometry}
\usepackage[margin=2cm]{geometry}
\usepackage{float}
\usepackage{multicol}
\usepackage[pdftex]{graphicx}
\usepackage[english]{babel}
\usepackage{sidecap}
\usepackage[font=small,labelfont=bf]{caption}

%----------------------------------------------------------

\makeatletter
\newenvironment{tablehere}
  {\def\@captype{table}}
  {}

\newenvironment{figurehere}
  {\def\@captype{figure}}
  {}
\makeatother

\begin{document}

\maketitle

\begin{abstract}
DNA microarrays allow biologists to capture the expression of hundreds of thousands of genes in a single tissue sample.TODO:CITE In this paper, we explore the possibility of using this gene expression data to identify gene signatures that allow for accurate classification by cell type. We describe our work on two datasets, one derived from cancerous and normal breast tissue, and one derived from blood cells. For the first dataset, we attempted to use feature selection to find the genes that indicate cancerous breast tissue. This problem turned out to be easy in the sense that most sets of genes result in high classifier performance, so we concluded that we needed a more difficult classification problem in order to find a gene signature of biological significance. In the second dataset, cells were labeled by flow cytometry according to their stage in hematopoietic differentiation. For this multiclass classification problem, we identified gene signatures that give reasonably good classification results. We also report our classifier's results when run on test datasets with early progenitors and AML (Acute Myeloid Leukemia)  cells, where the classification of cancerous cells is of particular interest because accurate classification would allow us to determine which types of normal cells cancerous cells develop from.
 
\end{abstract}

\begin{multicols}{2}

\section{Introduction}
The wealth of gene expression data generated by improved microarray technology that has triggered research on applying computational--and in particular statistical and machine learning methods--to biological problems. On the topic of cancer, for example, work has been done on predicting survival \cite{haibe, buyse}, determining which genes' expression correlate with certain diseases \cite{haibe, sotiriou, abraham}, and classifying cancers by subtype. Popular approaches include entropy theory, chi-squared and t-statistics for feature selection, k-nearest neighbors, naive bayes, and support vector machines \cite{liu}.\\\\
In this paper, we describe our work on two gene expression datasets that we were directed to by Professor David Dill. In breast tissue dataset, cells were labeled as cancerous or normal, and we tried to use feature selection to find genes whose expression makes them good indicators to breast cancer. We found this binary classification problem to be too easy for it to be possible to identify a unique such set of genes. In view of this, we moved on to a more difficult problem. In the second dataset, human cells were labeled according to their stage in hematopoietic differentiation, a highly regulated process by which the body generates blood cells. The process is also an widely-studied model for multilineage differentiation in humans \cite{novershtern}. We embraced this problem because it involved multiclass classification, a field in which no dominant method has emerged, and we again tried to find gene signatures that provide good classification.\\\\
For this project we used Scikit-Learn, a collection of Python implementations of common machine learning algorithms available at http://scikit-learn.org.


\section{Binary}
\setcounter{subsection}{-1} %this makes it so that preprocessing is 2.0 so that 2.1 and 3.1 both refer to forward selection
\subsection{Dataset \& Preprocessing} 
In this section, we describe our attempts to use feature selection to identify a gene signature for breast cancer. The dataset was originally obtained from the National Cancer Institute’s Cancer Genome Atlas and includes expression data of 17814 genes for 599 people, of whom 533 have breast cancer and 66 do not. Data was obtained from Agilent G4502 microarrays.\\\\
We normalized the data to have mean 0 and standard deviation 1. At least one gene expression value was missing for each of 319 people. These values collectively pertained to 537 distinct genes and added up to a total of 1740 missing values. We set these values to be equal to the mean (0).

\subsection{Results \& Discussion}
We found out that this problem is very easy to solve. Naive Bayes, which operates under the very unrealistic assumption that the genes are independently expressed, got on average 98\% accuracy, 99\% precision and 99\% recall when tested with 75\% - 25\% cross validation. SVM with random feature selection gave on average 91\% accuracy, 91\% precision and 100\% recall. This means that any set of genes gives good predictions, which is on par with recent literature \cite{venet}, which in turns means that either this method cannot be used to find gene signatures or that almost all genes are significantly correlated with breast cancer.
\begin{tabular}{ | l | l | l | }
 \hline
    Method & Precision & Recall\\
  \hline 
Naive Bayes & 99\% & 99\% \\  \hline 
Logistic Regression with L1 & 99\% & 100\% \\  \hline 
SVM with Chi2 & 99\% & 100\% \\  \hline 
Backwards Selection & 99\% & 100\% \\  \hline 
SVM with Random 50 Genes & 91\% & 100\% \\  \hline 
>>>>>>> 4832037e56f05f81dc33266d45806dce3dd4b9a9
  \hline
\end{tabular}


\section{Multiclass}

\setcounter{subsection}{-1}

\subsection{Dataset}
This section regards our attempt to develop an algorithm that classifies cells into their stage of hematopoietic differentiation. The method for obtaining the dataset along with further information about the dataset is in \cite{novershtern}. It contained data from 211 cells. Each cell had gene expression levels for 11927 genes, and each cell is classified in one of 38 categories. This paper grouped the 38 classes into 5 more general ones and found gene signatures for these 5 classes. Our goal was to refine this grouping, i.e., find signatures that distinguish among a larger set of classes. %FIXME: mention Dill’s preprocessing

\subsection{Methods}
\subsubsection{Feature selection and regularization}
As is usually the case with microarray data, the number of features in our dataset drastically exceeded the number of training examples. Therefore we added feature selection and regularization to prevent overfitting. We used two straightforward methods: a univariate feature selection method based on a measure of dependence between random variables, and a regularization method that results in sparse solutions (by driving many coefficients to 0).

\subsubsection{Handling multiclass classification}
Multiclass classifiers fall into roughly two types: extensions of binary classifiers versus repeated application of binary classifiers.  Our multiclass classifier consists of extensions of binary classifiers. We tried three ways to build a multiclass classifier out of binary classifiers: one-vs-all, one-vs-one and Error-Correcting Output Coding (ECOC). In one versus all, a binary classifier is built for each category, each one having the positive class as that category and the negative class as the union of the rest. In one-vs-one, a binary classifier is built for each pair of classes, ignoring all the remaining categories. In ECOC, a sequence of binary classifiers are built; for each one of them, a randomly chosen subset of the categories is the positive class, and the union of the remaining classes is the negative class. In all of them, the predicted category for a new example is the most consistently predicted category. For more detail on these generalization methods, see \cite{zhang}.

\subsubsection{Adjusting class-weights}
In the standard SVM framework each class is weighed equally. Since we are worse at classifying cells that are infrequent in our training set, we tried adjusting weights on the penalty term of the SVM to be inversely proportional to class frequencies. This would cause our classifier to sacrifice confidence on most classes with hopes of improving classification of the rare classes. We thought that such sacrifice could be worth it since our classifier did very well on the prevalent classes. We found that this (slightly) decreased our leave-one-out cross- validation performance.
\subsection{Results \& Discussion}
\begin{figure*}[t]
\centering
 \includegraphics[width=160mm]{differentiation.jpg}
 \caption{Hematopoeitic Cell Differentiation. Black indicates early progenitors that were in our 211-array training set. Pink indicates early progenitors that were present only in a test set. Blue indicates all other cells present in our training set. HSC: hematopoeitic stem cell; MPP: late multipotent progenitor; CMP: common myeloid progenitor; MEP: megakaryocyte/erythroid progenitor; ERY: erythrocyte; MEGA: megakaryocytes; GMP: granulocyte/monocyte progenitor; GRAN:  granulocyte; MONO: monocyte; EOS2: eosinophil; BASO:  basophil; DEND: dendritic; PRE-BCELL: early or pro-B cell; BCELL: naive, mature, able to switch, or switched B-cell; NK: natural killer; TCELL: T-cells.}
\end{figure*}
Initially we repeatedly ran SVM with all 38 classes distinguished and varied kernel, C, feature selection and generalization method. We found that the optimal choice was linear kernel, C = 125, L1 regularization (which automatically determines the number of features) and one-vs-all. This led to 78.6\% accuracy with leave-one-out cross-validation. Here we observed that the most common misclassifications were ERY2, ERY3 and ERY4 mapping to each other, so we turned these 3 categories into a single one. This means we are assuming that the information in our dataset is not enough to distinguish them or that they are too biologically similar. We did the same with MEGA1 and MEGA2. This results in 35 classes. Accuracy rose to 86.2\%. \cite{zhang} reported no more than 68\% for their dataset with 14 classes, the highest number of classes they worked with.\\\\	
	We then tried to use our classifier on a test set. On two 6-array test sets, we were able to identify granulocytes correctly with our best-performing (as determined through cross-validation on the 211-array data set) one-vs-one SVM. We also attempted to classify a 27-array test set of early progenitors (TODO ADD BIO CONTEXT) by using a two stage classification. We classified all the cells using our best one-vs-all SVM. Then, we selected out all the cells classified as any one of the five early progenitors (HSCs, MEPs, CMPs, GMPs). Finally, we used a one-vs-all SVM trained on only the early progenitor cells. We opted for a two-layer approach because our initial classifier was particularly deficient in classifying early progenitors. Six of the classifications were exactly correct, and 13 others were close (i.e. no more than one cell type away in the lineage (TODO ADD WHAT THIS IS / ADD PICTURE?)), where 8 of those 13 were cell-types not present in the 211-array test set (and therefore could not have been classified exactly correctly).

\begin{figurehere}
 \includegraphics[width=70mm]{graph.jpg}
 
 \caption{Results}
\end{figurehere}	

\begin{figurehere}
 \hspace*{-10mm}
  \centerline{
\includegraphics[width=90mm]{confusionmatrix.jpg}}
 \caption{Confusion Matrix for OvA SVM. X-axis is predicted,Y-axis is actual}
\end{figurehere}	

\subsection{Relevance and interpretation}
\cite{novershtern} groups the 38 classes into 5 larger classes in order to get gene signatures. Since our classifier consistently classifies 21 classes with no false negatives, we were able to retrieve gene signatures for all of these by looking at the genes picked by feature selection by the respective classifier (one for each cell, as in one-vs-all). Some of the gene expressions in our gene signatures were as far as 2 standard deviations away from the mean (standard deviation and mean computed over all classes). The size of the gene signatures (determined by L1 regularization) ranges from 8 to 53 genes and averages to 26. Random sets of 30 genes give an average 30\% accuracy on leave-one-out cross-validation (against 86.2\% for our selected genes), which gives credibility to our signatures.
The following classes are predicted with no false negatives (and hence provide reasonable gene signatures): BASO, BCELLa1, BCELLa2, BCELLa3, BCELLa4, DENDa1, DENDa2, ERY3-5 (a single cluster), GRAN1, GRAN3, HSC1, MEGA1-2 (a single cluster), NKa1, NKa2, NKa3, TCEL2, TCEL3, TCEL4, TCEL5, TCEL6, TCEL7, TCEL8.\\

\begin{tablehere}
\centering
\begin{tabular}{ | l | l | l | }
 \hline
Weight & Gene & Expression \\ \hline
0.58 & C18orf1 & 0.65\\  \hline
0.25 & SLC43A1 & 0.04\\ \hline
0.18 & MFSD7 & 0.91\\ \hline
0.12 & ADRA2A & 1.45\\ \hline
0.08 & PHGDH & -0.178\\ \hline
0.08 & PARG & 0.205\\ \hline
0.06 & ZBTB1 & 1.32\\ \hline
0.05 & TRAJ28 & 0.67\\ \hline
\end{tabular}
 \caption{Gene signature for BCELLa2}
\end{tablehere}
\vspace{3 mm}
The following have particularly high number of false negatives: CMP, ERY1, GMP, TCEL1.
TODO: -> Indicates large within-individual variation of gene expression along differentiation
TODO: -> impaired or blocked hematopoietic differentiation is a defining characteristic of leukemia

\subsection{Further Work}
One of the most important problems to be addressed in future work is that of classifying cancerous cells into their stage of differentiation. This is very difficult because some of the genes in cancerous cells are distorted.\\
	Our works also shows the importance of collecting more microarray data, because our classifier does very well with the classes for which we have more training examples. This gives hope that obtaining more microarray data, which is currently expensive, will allow for increasingly accurate classifiers and gene signatures.\\
	On a related note, our classifier is inefficient at distinguishing MEP, CMP, GMP and ERY1 from one another. Future work could restrict its attention to these cells.\\
	This dataset might also contain errors in the process of obtaining the microarray (in purifying, for instance). One indication of this is that one of the cells labeled as GMP consistently gets mapped to TCELLs, classes that are very far from each other in the differentiation process. This seems not to be just a problem with the algorithm since this mistake persisted even when our classifier correctly classified all the remaining GMPs. Therefore, it might be useful to apply statistical methods to identify outliers in this dataset (and make this process standard for microarray data, since they are very error-prone) and ignore these outliers.

\section{Acknowledgements}
Thank you to Professor David Dill (Stanford CS) for his patient guidance and for providing us with preprocessed and ready-to-use gene expression data. Thank you to Professor Ravi Majeti (Stanford Cancer Center) for the AML test set, to Professor Stephen Boyd (Stanford EE) for the initial project idea, and to Yifei Meng  (Computational Biology 15’) for help in evaluating test set results.

\end{multicols}

\begin{thebibliography}{11}

\bibitem{haibe} Haibe-Kains, B., Desmedt, C., Piette, F., Buyse, M., Cardoso, F., van't Veer, L., \& Sotiriou, C. Comparison of prognostic gene expression signatures for breast cancer. BMC Genomics, 9:1-9. 2008. doi:10.1186/1471-2164-9-394


\bibitem{buyse} Buyse, M., Loi, S., van't Veer, L., Viale, G., Delorenzi, M., Glas, A. M., \& ... Piccart, M. J. Validation and Clinical Utility of a 70-Gene Prognostic Signature for Women With Node-Negative Breast Cancer. JNCI: Journal Of The National Cancer Institute, 98(17):1183-1192, 2006. doi:10.1093/jnci/djj329

\bibitem{sotiriou} Sotiriou, C., \& Pusztai, L. Gene-Expression Signatures in Breast Cancer. New England Journal Of Medicine, 360(8): 790-800, 2009. doi:10.1056/NEJMra0801289

\bibitem{abraham} Abraham, G., Kowalczyk, A., Loi, S., Haviv, I., \& Zobel, J. Prediction of breast cancer prognosis using geneset statistics provides signature stability and biological context. BMC Bioinformatics,11:277-291, 2010. doi:10.1186/1471-2105-11-277

\bibitem{liu} Liu, H., Li, J., \& Wong, L. A comparative study on feature selection and classification methods using gene expression profiles and proteomic patterns. Genome Informatics. International Conference On Genome Informatics, 13:51-60, 2002.

\bibitem{venet} Venet, D., Dumont, J. E., \& Detours, V. Most Random Gene Expression Signatures Are Significantly Associated with Breast Cancer Outcome. Plos Computational Biology, 7(10):1-8, 2011. doi:10.1371/journal.pcbi.1002240

\bibitem{zhang} Li, T., Zhang, C. \& Ogihata, M. A comparative study of feature selection and multiclass classification methods for tissue classification based on gene expression. Bioinformatics 20(15): 2429-2437, 2004 doi:10.1093/bioinformatics/bth267

\bibitem{novershtern} Novershtern, N., Subramanian, A., Lawton, L. N., Mak, R. H., Haining, W.N., McConkey, M.E., Habib, N., Yosef, N., Chang, C.Y., Shay, T., Frampton, G.M., Drake, A.C., Leskov, I., Nilsson, B., Preffer, F., Dombkowski, D., Evans, J.W., Liefeld, T., Smutko, J.S., Chen, J., Friedman, N., Young, R.A., Golub, T.R., Regev, A., \& Ebert, B.L. Densely Interconnected Transcriptional Circuits Control Cell States in Human Hematopoiesis. Cell 144: 296-309, 2011. doi:10.1016/j.cell.2011.01.004

\end{thebibliography}
\end{document}
